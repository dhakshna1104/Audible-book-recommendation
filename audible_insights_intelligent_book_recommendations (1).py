# -*- coding: utf-8 -*-
"""Audible Insights: Intelligent Book Recommendations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18GQud8bvwXRc9LTtTh2w5cueOxZFz_zQ
"""

###Data Preparation:

import pandas as pd
import numpy as np
import re

# Load the datasets
df1 = pd.read_csv("/content/Audible_Catlog.csv")
df2 = pd.read_csv("/content/Audible_Catlog_Advanced_Features.csv")

# Merge datasets on 'Book Name' and 'Author'
merged_df = pd.merge(df1, df2, on=["Book Name", "Author"], suffixes=('_x', ''))

# Drop duplicate columns after merge
merged_df.drop(columns=["Rating_x", "Number of Reviews_x", "Price_x"], inplace=True)

# Rename retained columns for clarity
merged_df.rename(columns={
    "Rating": "Rating",
    "Number of Reviews": "Number of Reviews",
    "Price": "Price"
}, inplace=True)

# Remove duplicates based on Book Name and Author
merged_df.drop_duplicates(subset=["Book Name", "Author"], inplace=True)

# Drop rows with missing critical information
merged_df.dropna(subset=["Rating", "Number of Reviews", "Price", "Listening Time"], inplace=True)

# Convert 'Listening Time' into total minutes
def convert_time_to_minutes(time_str):
    match = re.match(r'(?:(\d+)\s*hours?)?\s*(?:(\d+)\s*minutes?)?', time_str.strip())
    if match:
        hours = int(match.group(1)) if match.group(1) else 0
        minutes = int(match.group(2)) if match.group(2) else 0
        return hours * 60 + minutes
    return np.nan

merged_df['Listening Time (min)'] = merged_df['Listening Time'].apply(convert_time_to_minutes)

# Extract genre from 'Ranks and Genre'
def extract_genres(text):
    if pd.isna(text):
        return None
    genre_matches = re.findall(r'in (.*?) \(See', text)
    return genre_matches[0] if genre_matches else None

merged_df['Genre'] = merged_df['Ranks and Genre'].apply(extract_genres)

# (Optional) Save the cleaned dataset
# merged_df.to_csv("Cleaned_Audible_Catalog.csv", index=False)

# Preview cleaned data
print(merged_df[['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price', 'Listening Time (min)', 'Genre']].head())

##Merging
merged_df.to_csv("Cleaned_Audible_Catalog.csv", index=False)

### EDA
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your cleaned dataset
df = pd.read_csv("/content/Cleaned_Audible_Catalog.csv")

# Set up visualization styles
sns.set(style="whitegrid")
plt.figure(figsize=(8, 3))

# 1. Ratings Distribution
sns.histplot(df['Rating'], bins=10, kde=True, color="skyblue")
plt.title("Distribution of Book Ratings")
plt.xlabel("Rating")
plt.ylabel("Count")
plt.show()

# 2. Top Genres by Count
top_genres = df['Genre'].value_counts().head(10)
plt.figure(figsize=(8, 3))
sns.barplot(x=top_genres.values, y=top_genres.index, palette="viridis")
plt.title("Top 10 Most Common Genres")
plt.xlabel("Number of Books")
plt.ylabel("Genre")
plt.show()

# 3. Top-Rated Books (Rating ‚â• 4.8)
top_books = df[df['Rating'] >= 4.8][['Book Name', 'Author', 'Rating']].drop_duplicates()
print("\nTop-Rated Books (Rating ‚â• 4.8):")
print(top_books)

# (Optional) If you had a publication year column:
# sns.lineplot(data=df, x='Publication Year', y='Rating')

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

# Load cleaned dataset
df = pd.read_csv("/content/Cleaned_Audible_Catalog.csv")

# Combine 'Book Name' and 'Description' for NLP features
df['Text'] = df['Book Name'].fillna('') + " " + df['Description'].fillna('')

# TF-IDF Vectorization
tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
X_tfidf = tfidf.fit_transform(df['Text'])

# K-Means Clustering (choose k based on elbow method or trial)
k = 5
kmeans = KMeans(n_clusters=k, random_state=42)
df['Cluster'] = kmeans.fit_predict(X_tfidf)

# Dimensionality reduction for visualization
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_tfidf.toarray())

# Plotting the clusters
plt.figure(figsize=(5,3))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=df['Cluster'], palette="Set2")
plt.title("K-Means Clustering of Books Based on Title & Description")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.legend(title='Cluster')
plt.show()

# Optional: Explore one of the clusters
for i in range(k):
    print(f"\nüìö Cluster {i} Example Titles:")
    print(df[df['Cluster'] == i]['Book Name'].head(5).to_string(index=False))

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

# TF-IDF on Descriptions
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['Description'].fillna(""))

# Compute cosine similarity
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

# Book title to index mapping
indices = pd.Series(df.index, index=df['Book Name']).drop_duplicates()

def recommend_books(title, cosine_sim=cosine_sim, top_n=5):
    idx = indices.get(title)
    if idx is None:
        return f"Book '{title}' not found."

    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    book_indices = [i[0] for i in sim_scores]

    return df.iloc[book_indices][['Book Name', 'Author', 'Genre']]

# Example:
# recommend_books("Atomic Habits")

!pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.metrics.pairwise import linear_kernel
# import seaborn as sns
# import matplotlib.pyplot as plt
# 
# # Load cleaned dataset
# df = pd.read_csv("Cleaned_Audible_Catalog.csv")
# 
# # TF-IDF for content-based similarity
# tfidf = TfidfVectorizer(stop_words='english')
# tfidf_matrix = tfidf.fit_transform(df['Description'].fillna(''))
# cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
# indices = pd.Series(df.index, index=df['Book Name']).drop_duplicates()
# 
# # Recommend books by content similarity
# def recommend_books(title, top_n=5):
#     idx = indices.get(title)
#     if idx is None:
#         return pd.DataFrame({'Message': [f"'{title}' not found."]})
#     sim_scores = list(enumerate(cosine_sim[idx]))
#     sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
#     book_indices = [i[0] for i in sim_scores]
#     return df.iloc[book_indices][['Book Name', 'Author', 'Genre', 'Rating']]
# 
# # Streamlit UI
# st.title("üìö Audible Book Recommendation App")
# 
# # Sidebar navigation
# option = st.sidebar.radio("Go to", ['üìñ Recommend by Book', 'üéØ Recommend by Genre', 'üìä EDA'])
# 
# # Page 1: Recommend by Book
# if option == 'üìñ Recommend by Book':
#     st.header("üîç Find Similar Books")
#     book_title = st.selectbox("Choose a book you like", sorted(df['Book Name'].unique()))
#     if st.button("Recommend"):
#         results = recommend_books(book_title)
#         st.subheader("üìö Recommended Books:")
#         st.dataframe(results)
# 
# # Page 2: Recommend by Genre
# elif option == 'üéØ Recommend by Genre':
#     st.header("üéß Genre-Based Book Finder")
#     genre = st.selectbox("Choose a genre", sorted(df['Genre'].dropna().unique()))
#     top_n = st.slider("Number of books to show", 1, 10, 5)
#     filtered = df[df['Genre'] == genre].sort_values(by="Rating", ascending=False).head(top_n)
#     st.dataframe(filtered[['Book Name', 'Author', 'Rating', 'Listening Time (min)']])
# 
# # Page 3: EDA
# elif option == 'üìä EDA':
#     st.header("üìä Exploratory Data Analysis")
# 
#     st.subheader("Distribution of Ratings")
#     fig1, ax1 = plt.subplots()
#     sns.histplot(df['Rating'], bins=10, kde=True, ax=ax1, color="skyblue")
#     st.pyplot(fig1)
# 
#     st.subheader("Top Genres")
#     top_genres = df['Genre'].value_counts().head(10)
#     fig2, ax2 = plt.subplots()
#     sns.barplot(x=top_genres.values, y=top_genres.index, ax=ax2, palette="viridis")
#     st.pyplot(fig2)
#

import urllib
print("Password/Enpoint IP for localtunnel is:",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip("\n"))

get_ipython().system('streamlit run app.py & npx localtunnel --port 8501')